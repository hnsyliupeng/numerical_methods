{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Generative Adversarial Networks (DCGANs) on the Fashion MNIST dataset using Keras and TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mfayemiwo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mfayemiwo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mfayemiwo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mfayemiwo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mfayemiwo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mfayemiwo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN:\n",
    "    @staticmethod\n",
    "    def build_generator(dim, depth, channels=1, inputDim=100,\n",
    "        outputDim=512):\n",
    "        # initialize the model along with the input shape to be\n",
    "        # \"channels last\" and the channels dimension itself\n",
    "        model = Sequential()\n",
    "        inputShape = (dim, dim, depth)\n",
    "        chanDim = -1\n",
    "        \n",
    "        # first set of FC => RELU => BN layers\n",
    "        model.add(Dense(input_dim=inputDim, units=outputDim))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        # second set of FC => RELU => BN layers, this time preparing the number of FC nodes to be\n",
    "        # reshaped into a volume\n",
    "        model.add(Dense(dim * dim * depth))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        # reshape the output of the previous layer set, upsample + apply a transposed convolution, RELU, and BN\n",
    "        model.add(Reshape(inputShape))\n",
    "        model.add(Conv2DTranspose(32, (5, 5), strides=(2, 2),\n",
    "            padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        \n",
    "        # apply another upsample and transposed convolution, but this time output the TANH activation\n",
    "        model.add(Conv2DTranspose(channels, (5, 5), strides=(2, 2),\n",
    "            padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        # return the generator model\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def build_discriminator(width, height, depth, alpha=0.2):\n",
    "        # initialize the model along with the input shape to be \"channels last\"\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        # first set of CONV => RELU layers\n",
    "        model.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2, 2),\n",
    "            input_shape=inputShape))\n",
    "        model.add(LeakyReLU(alpha=alpha))\n",
    "        # second set of CONV => RELU layers\n",
    "        model.add(Conv2D(64, (5, 5), padding=\"same\", strides=(2, 2)))\n",
    "        model.add(LeakyReLU(alpha=alpha))\n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=alpha))\n",
    "        # sigmoid layer outputting a single value\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "        # return the discriminator model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from sklearn.utils import shuffle\n",
    "from imutils import build_montages\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST dataset...\n"
     ]
    }
   ],
   "source": [
    "# load the Fashion MNIST dataset and stack the training and testing data points so we have\n",
    "# additional training data\n",
    "print(\"[INFO] loading MNIST dataset...\")\n",
    "((trainX, _), (testX, _)) = fashion_mnist.load_data()\n",
    "trainImages = np.concatenate([trainX, testX])\n",
    "# add in an extra dimension for the channel and scale the images into the range [-1, 1]\n",
    "# (which is the range of the tanh function)\n",
    "trainImages = np.expand_dims(trainImages, axis=-1)\n",
    "trainImages = (trainImages.astype(\"float\") - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the epochs and batch size in convenience variables, then initialize our learning rate\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "INIT_LR = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building generator...\n",
      "WARNING:tensorflow:From /home/mfayemiwo/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[INFO] building discriminator...\n"
     ]
    }
   ],
   "source": [
    "# build the generator\n",
    "print(\"[INFO] building generator...\")\n",
    "gen = DCGAN.build_generator(7, 64, channels=1)\n",
    "# build the discriminator\n",
    "print(\"[INFO] building discriminator...\")\n",
    "disc = DCGAN.build_discriminator(28, 28, 1)\n",
    "discOpt = Adam(lr=INIT_LR, beta_1=0.5, decay=INIT_LR / NUM_EPOCHS)\n",
    "disc.compile(loss=\"binary_crossentropy\", optimizer=discOpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building GAN...\n"
     ]
    }
   ],
   "source": [
    "# build the adversarial model by first setting the discriminator to\n",
    "# *not* be trainable, then combine the generator and discriminator\n",
    "# together\n",
    "print(\"[INFO] building GAN...\")\n",
    "disc.trainable = False\n",
    "ganInput = Input(shape=(100,))\n",
    "ganOutput = disc(gen(ganInput))\n",
    "gan = Model(ganInput, ganOutput)\n",
    "# compile the GAN\n",
    "ganOpt = Adam(lr=INIT_LR, beta_1=0.5, decay=INIT_LR / NUM_EPOCHS)\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=discOpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting training...\n",
      "[INFO] starting epoch 1 of 5...\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:From /home/mfayemiwo/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[INFO] Step 1_0: discriminator_loss=0.697938, adversarial_loss=0.643400\n",
      "[INFO] Step 1_25: discriminator_loss=0.046956, adversarial_loss=0.013209\n",
      "[INFO] Step 1_50: discriminator_loss=0.000928, adversarial_loss=0.001270\n",
      "[INFO] Step 1_75: discriminator_loss=0.000252, adversarial_loss=0.000780\n",
      "[INFO] Step 1_100: discriminator_loss=0.000138, adversarial_loss=0.000669\n",
      "[INFO] Step 1_125: discriminator_loss=0.000204, adversarial_loss=0.001067\n",
      "[INFO] Step 1_150: discriminator_loss=0.000315, adversarial_loss=0.000597\n",
      "[INFO] Step 1_175: discriminator_loss=0.000360, adversarial_loss=0.000288\n",
      "[INFO] Step 1_200: discriminator_loss=0.000639, adversarial_loss=0.002250\n",
      "[INFO] Step 1_225: discriminator_loss=0.098759, adversarial_loss=2.214174\n",
      "[INFO] Step 1_250: discriminator_loss=0.205589, adversarial_loss=1.111233\n",
      "[INFO] Step 1_275: discriminator_loss=0.322560, adversarial_loss=1.347596\n",
      "[INFO] Step 1_300: discriminator_loss=0.440389, adversarial_loss=1.194285\n",
      "[INFO] Step 1_325: discriminator_loss=0.491244, adversarial_loss=2.261398\n",
      "[INFO] Step 1_350: discriminator_loss=0.433429, adversarial_loss=1.382495\n",
      "[INFO] Step 1_375: discriminator_loss=0.437696, adversarial_loss=1.930125\n",
      "[INFO] Step 1_400: discriminator_loss=0.473288, adversarial_loss=0.928033\n",
      "[INFO] Step 1_425: discriminator_loss=0.416016, adversarial_loss=1.701138\n",
      "[INFO] Step 1_450: discriminator_loss=0.423570, adversarial_loss=1.381399\n",
      "[INFO] Step 1_475: discriminator_loss=0.413350, adversarial_loss=1.185521\n",
      "[INFO] Step 1_500: discriminator_loss=0.408817, adversarial_loss=1.583829\n",
      "[INFO] Step 1_525: discriminator_loss=0.512879, adversarial_loss=0.876086\n",
      "[INFO] Step 1_545: discriminator_loss=0.456085, adversarial_loss=0.819529\n",
      "[INFO] starting epoch 2 of 5...\n",
      "[INFO] Step 2_0: discriminator_loss=0.493338, adversarial_loss=1.471529\n",
      "[INFO] Step 2_25: discriminator_loss=0.520322, adversarial_loss=0.942739\n",
      "[INFO] Step 2_50: discriminator_loss=0.512486, adversarial_loss=1.577776\n",
      "[INFO] Step 2_75: discriminator_loss=0.497870, adversarial_loss=1.781319\n",
      "[INFO] Step 2_100: discriminator_loss=0.533517, adversarial_loss=0.737731\n",
      "[INFO] Step 2_125: discriminator_loss=0.522475, adversarial_loss=1.615172\n",
      "[INFO] Step 2_150: discriminator_loss=0.523380, adversarial_loss=0.913159\n",
      "[INFO] Step 2_175: discriminator_loss=0.525102, adversarial_loss=1.360306\n",
      "[INFO] Step 2_200: discriminator_loss=0.544691, adversarial_loss=0.597454\n",
      "[INFO] Step 2_225: discriminator_loss=0.478076, adversarial_loss=1.372184\n",
      "[INFO] Step 2_250: discriminator_loss=0.488859, adversarial_loss=1.190214\n",
      "[INFO] Step 2_275: discriminator_loss=0.592100, adversarial_loss=0.658942\n",
      "[INFO] Step 2_300: discriminator_loss=0.508942, adversarial_loss=1.659649\n",
      "[INFO] Step 2_325: discriminator_loss=0.491140, adversarial_loss=1.568194\n",
      "[INFO] Step 2_350: discriminator_loss=0.487271, adversarial_loss=1.474095\n",
      "[INFO] Step 2_375: discriminator_loss=0.580032, adversarial_loss=2.004380\n",
      "[INFO] Step 2_400: discriminator_loss=0.522400, adversarial_loss=0.805771\n",
      "[INFO] Step 2_425: discriminator_loss=0.488597, adversarial_loss=1.436851\n",
      "[INFO] Step 2_450: discriminator_loss=0.526291, adversarial_loss=0.992873\n",
      "[INFO] Step 2_475: discriminator_loss=0.479368, adversarial_loss=1.453897\n",
      "[INFO] Step 2_500: discriminator_loss=0.488267, adversarial_loss=1.014792\n",
      "[INFO] Step 2_525: discriminator_loss=0.581364, adversarial_loss=0.580704\n",
      "[INFO] Step 2_545: discriminator_loss=0.512917, adversarial_loss=0.711323\n",
      "[INFO] starting epoch 3 of 5...\n",
      "[INFO] Step 3_0: discriminator_loss=0.593283, adversarial_loss=1.594283\n",
      "[INFO] Step 3_25: discriminator_loss=0.556826, adversarial_loss=0.824811\n",
      "[INFO] Step 3_50: discriminator_loss=0.506135, adversarial_loss=1.099917\n",
      "[INFO] Step 3_75: discriminator_loss=0.500229, adversarial_loss=1.559212\n",
      "[INFO] Step 3_100: discriminator_loss=0.483580, adversarial_loss=1.307180\n",
      "[INFO] Step 3_125: discriminator_loss=0.500625, adversarial_loss=1.162204\n",
      "[INFO] Step 3_150: discriminator_loss=0.546421, adversarial_loss=1.097148\n",
      "[INFO] Step 3_175: discriminator_loss=0.554830, adversarial_loss=0.772491\n",
      "[INFO] Step 3_200: discriminator_loss=0.495593, adversarial_loss=1.053613\n",
      "[INFO] Step 3_225: discriminator_loss=0.486414, adversarial_loss=1.167239\n",
      "[INFO] Step 3_250: discriminator_loss=0.511217, adversarial_loss=0.801029\n",
      "[INFO] Step 3_275: discriminator_loss=0.588951, adversarial_loss=1.212704\n",
      "[INFO] Step 3_300: discriminator_loss=0.525767, adversarial_loss=0.767185\n",
      "[INFO] Step 3_325: discriminator_loss=0.532170, adversarial_loss=1.095420\n",
      "[INFO] Step 3_350: discriminator_loss=0.488003, adversarial_loss=1.023937\n",
      "[INFO] Step 3_375: discriminator_loss=0.472007, adversarial_loss=1.133373\n",
      "[INFO] Step 3_400: discriminator_loss=0.548397, adversarial_loss=1.503227\n",
      "[INFO] Step 3_425: discriminator_loss=0.528546, adversarial_loss=0.993805\n",
      "[INFO] Step 3_450: discriminator_loss=0.567155, adversarial_loss=0.928691\n",
      "[INFO] Step 3_475: discriminator_loss=0.624100, adversarial_loss=1.598376\n",
      "[INFO] Step 3_500: discriminator_loss=0.521139, adversarial_loss=0.996408\n",
      "[INFO] Step 3_525: discriminator_loss=0.598306, adversarial_loss=0.918998\n",
      "[INFO] Step 3_545: discriminator_loss=0.564516, adversarial_loss=0.992067\n",
      "[INFO] starting epoch 4 of 5...\n",
      "[INFO] Step 4_0: discriminator_loss=0.571943, adversarial_loss=0.995182\n",
      "[INFO] Step 4_25: discriminator_loss=0.525825, adversarial_loss=0.725795\n",
      "[INFO] Step 4_50: discriminator_loss=0.558352, adversarial_loss=1.158375\n",
      "[INFO] Step 4_75: discriminator_loss=0.524575, adversarial_loss=1.109188\n",
      "[INFO] Step 4_100: discriminator_loss=0.534304, adversarial_loss=0.864147\n",
      "[INFO] Step 4_125: discriminator_loss=0.557867, adversarial_loss=0.929134\n",
      "[INFO] Step 4_150: discriminator_loss=0.584056, adversarial_loss=0.972110\n",
      "[INFO] Step 4_175: discriminator_loss=0.580698, adversarial_loss=0.974813\n",
      "[INFO] Step 4_200: discriminator_loss=0.549489, adversarial_loss=0.844237\n",
      "[INFO] Step 4_225: discriminator_loss=0.557868, adversarial_loss=1.165122\n",
      "[INFO] Step 4_250: discriminator_loss=0.542441, adversarial_loss=0.981184\n",
      "[INFO] Step 4_275: discriminator_loss=0.569508, adversarial_loss=0.790535\n",
      "[INFO] Step 4_300: discriminator_loss=0.557891, adversarial_loss=1.149256\n",
      "[INFO] Step 4_325: discriminator_loss=0.574008, adversarial_loss=0.949546\n",
      "[INFO] Step 4_350: discriminator_loss=0.509293, adversarial_loss=0.713221\n",
      "[INFO] Step 4_375: discriminator_loss=0.563020, adversarial_loss=1.305475\n",
      "[INFO] Step 4_400: discriminator_loss=0.561833, adversarial_loss=0.882174\n",
      "[INFO] Step 4_425: discriminator_loss=0.547368, adversarial_loss=0.900491\n",
      "[INFO] Step 4_450: discriminator_loss=0.568574, adversarial_loss=0.860057\n",
      "[INFO] Step 4_475: discriminator_loss=0.594502, adversarial_loss=1.042088\n",
      "[INFO] Step 4_500: discriminator_loss=0.588686, adversarial_loss=0.838853\n",
      "[INFO] Step 4_525: discriminator_loss=0.564903, adversarial_loss=0.900396\n",
      "[INFO] Step 4_545: discriminator_loss=0.586379, adversarial_loss=0.917143\n",
      "[INFO] starting epoch 5 of 5...\n",
      "[INFO] Step 5_0: discriminator_loss=0.585731, adversarial_loss=1.027532\n",
      "[INFO] Step 5_25: discriminator_loss=0.557746, adversarial_loss=0.736310\n",
      "[INFO] Step 5_50: discriminator_loss=0.578523, adversarial_loss=1.139130\n",
      "[INFO] Step 5_75: discriminator_loss=0.535942, adversarial_loss=0.987584\n",
      "[INFO] Step 5_100: discriminator_loss=0.566856, adversarial_loss=1.204568\n",
      "[INFO] Step 5_125: discriminator_loss=0.562527, adversarial_loss=0.959219\n",
      "[INFO] Step 5_150: discriminator_loss=0.588397, adversarial_loss=0.823803\n",
      "[INFO] Step 5_175: discriminator_loss=0.624656, adversarial_loss=1.261820\n",
      "[INFO] Step 5_200: discriminator_loss=0.562979, adversarial_loss=0.776573\n",
      "[INFO] Step 5_225: discriminator_loss=0.572404, adversarial_loss=0.845421\n",
      "[INFO] Step 5_250: discriminator_loss=0.601232, adversarial_loss=1.256209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Step 5_275: discriminator_loss=0.587682, adversarial_loss=1.076912\n",
      "[INFO] Step 5_300: discriminator_loss=0.553686, adversarial_loss=0.873782\n",
      "[INFO] Step 5_325: discriminator_loss=0.610920, adversarial_loss=0.756198\n",
      "[INFO] Step 5_350: discriminator_loss=0.526347, adversarial_loss=0.728220\n",
      "[INFO] Step 5_375: discriminator_loss=0.556878, adversarial_loss=1.044341\n",
      "[INFO] Step 5_400: discriminator_loss=0.594185, adversarial_loss=0.865543\n",
      "[INFO] Step 5_425: discriminator_loss=0.594914, adversarial_loss=0.833852\n",
      "[INFO] Step 5_450: discriminator_loss=0.615390, adversarial_loss=1.130425\n",
      "[INFO] Step 5_475: discriminator_loss=0.578268, adversarial_loss=1.076522\n",
      "[INFO] Step 5_500: discriminator_loss=0.576386, adversarial_loss=0.963277\n",
      "[INFO] Step 5_525: discriminator_loss=0.599806, adversarial_loss=0.952429\n",
      "[INFO] Step 5_545: discriminator_loss=0.621665, adversarial_loss=1.025011\n"
     ]
    }
   ],
   "source": [
    "# randomly generate some benchmark noise so we can consistently\n",
    "# visualize how the generative modeling is learning\n",
    "print(\"[INFO] starting training...\")\n",
    "benchmarkNoise = np.random.uniform(-1, 1, size=(256, 100))\n",
    "# loop over the epochs\n",
    "for epoch in range(0, NUM_EPOCHS):\n",
    "    # show epoch information and compute the number of batches per\n",
    "    # epoch\n",
    "    print(\"[INFO] starting epoch {} of {}...\".format(epoch + 1,\n",
    "        NUM_EPOCHS))\n",
    "    batchesPerEpoch = int(trainImages.shape[0] / BATCH_SIZE)\n",
    "    # loop over the batches\n",
    "    for i in range(0, batchesPerEpoch):\n",
    "        # initialize an (empty) output path\n",
    "        p = None\n",
    "        # select the next batch of images, then randomly generate\n",
    "        # noise for the generator to predict on\n",
    "        imageBatch = trainImages[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n",
    "        noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
    "        \n",
    "        # generate images using the noise + generator model\n",
    "        genImages = gen.predict(noise, verbose=0)\n",
    "        # concatenate the *actual* images and the *generated* images,\n",
    "        # construct class labels for the discriminator, and shuffle\n",
    "        # the data\n",
    "        X = np.concatenate((imageBatch, genImages))\n",
    "        y = ([1] * BATCH_SIZE) + ([0] * BATCH_SIZE)\n",
    "        y = np.reshape(y, (-1,))\n",
    "        (X, y) = shuffle(X, y)\n",
    "        # train the discriminator on the data\n",
    "        discLoss = disc.train_on_batch(X, y)\n",
    "        \n",
    "        # let's now train our generator via the adversarial model by\n",
    "        # (1) generating random noise and (2) training the generator\n",
    "        # with the discriminator weights frozen\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "        fakeLabels = [1] * BATCH_SIZE\n",
    "        fakeLabels = np.reshape(fakeLabels, (-1,))\n",
    "        ganLoss = gan.train_on_batch(noise, fakeLabels)\n",
    "        \n",
    "        \n",
    "        # check to see if this is the end of an epoch, and if so,\n",
    "        # initialize the output path\n",
    "        if i == batchesPerEpoch - 1:\n",
    "            p = [\"output\", \"epoch_{}_output.png\".format(\n",
    "                str(epoch + 1).zfill(4))]\n",
    "        # otherwise, check to see if we should visualize the current\n",
    "        # batch for the epoch\n",
    "        else:\n",
    "            # create more visualizations early in the training\n",
    "            # process\n",
    "            if epoch < 10 and i % 25 == 0:\n",
    "                p = [\"output\", \"epoch_{}_step_{}.png\".format(\n",
    "                    str(epoch + 1).zfill(4), str(i).zfill(5))]\n",
    "             # visualizations later in the training process are less\n",
    "            # interesting\n",
    "            elif epoch >= 10 and i % 100 == 0:\n",
    "                p = [\"output\", \"epoch_{}_step_{}.png\".format(\n",
    "                    str(epoch + 1).zfill(4), str(i).zfill(5))]\n",
    "                \n",
    "                \n",
    "        # check to see if we should visualize the output of the\n",
    "        # generator model on our benchmark data\n",
    "        if p is not None:\n",
    "            # show loss information\n",
    "            print(\"[INFO] Step {}_{}: discriminator_loss={:.6f}, \"\n",
    "                \"adversarial_loss={:.6f}\".format(epoch + 1, i,\n",
    "                    discLoss, ganLoss))\n",
    "            # make predictions on the benchmark noise, scale it back\n",
    "            # to the range [0, 255], and generate the montage\n",
    "            images = gen.predict(benchmarkNoise)\n",
    "            images = ((images * 127.5) + 127.5).astype(\"uint8\")\n",
    "            images = np.repeat(images, 3, axis=-1)\n",
    "            vis = build_montages(images, (28, 28), (16, 16))[0]\n",
    "            # write the visualization to disk\n",
    "            p = os.path.sep.join(p)\n",
    "            cv2.imwrite(p, vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
